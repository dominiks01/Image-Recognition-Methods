digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	125796978697840 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	125796989214704 [label=SoftmaxBackward0]
	125796989214608 -> 125796989214704
	125796989214608 [label=AddmmBackward0]
	125796989214752 -> 125796989214608
	125796999245936 [label="fc_layers.4.bias
 (10)" fillcolor=lightblue]
	125796999245936 -> 125796989214752
	125796989214752 [label=AccumulateGrad]
	125796989214512 -> 125796989214608
	125796989214512 [label=ReluBackward0]
	125796989214944 -> 125796989214512
	125796989214944 [label=AddmmBackward0]
	125796989215088 -> 125796989214944
	125796999245856 [label="fc_layers.2.bias
 (84)" fillcolor=lightblue]
	125796999245856 -> 125796989215088
	125796989215088 [label=AccumulateGrad]
	125796989215040 -> 125796989214944
	125796989215040 [label=ReluBackward0]
	125796989215232 -> 125796989215040
	125796989215232 [label=AddmmBackward0]
	125796989215376 -> 125796989215232
	125796999245696 [label="fc_layers.0.bias
 (120)" fillcolor=lightblue]
	125796999245696 -> 125796989215376
	125796989215376 [label=AccumulateGrad]
	125796989215328 -> 125796989215232
	125796989215328 [label=ViewBackward0]
	125796989215520 -> 125796989215328
	125796989215520 [label=AvgPool2DBackward0]
	125796989215664 -> 125796989215520
	125796989215664 [label=ReluBackward0]
	125796989215760 -> 125796989215664
	125796989215760 [label=ConvolutionBackward0]
	125796989215856 -> 125796989215760
	125796989215856 [label=AvgPool2DBackward0]
	125796989216048 -> 125796989215856
	125796989216048 [label=ReluBackward0]
	125796989216144 -> 125796989216048
	125796989216144 [label=ConvolutionBackward0]
	125796989216240 -> 125796989216144
	125796999245456 [label="conv_layers.0.weight
 (6, 3, 5, 5)" fillcolor=lightblue]
	125796999245456 -> 125796989216240
	125796989216240 [label=AccumulateGrad]
	125796989216192 -> 125796989216144
	125796999245616 [label="conv_layers.0.bias
 (6)" fillcolor=lightblue]
	125796999245616 -> 125796989216192
	125796989216192 [label=AccumulateGrad]
	125796989215808 -> 125796989215760
	125798845301376 [label="conv_layers.3.weight
 (16, 6, 5, 5)" fillcolor=lightblue]
	125798845301376 -> 125796989215808
	125796989215808 [label=AccumulateGrad]
	125796989215568 -> 125796989215760
	125798824478032 [label="conv_layers.3.bias
 (16)" fillcolor=lightblue]
	125798824478032 -> 125796989215568
	125796989215568 [label=AccumulateGrad]
	125796989215280 -> 125796989215232
	125796989215280 [label=TBackward0]
	125796998973904 -> 125796989215280
	125796999245536 [label="fc_layers.0.weight
 (120, 400)" fillcolor=lightblue]
	125796999245536 -> 125796998973904
	125796998973904 [label=AccumulateGrad]
	125796989214896 -> 125796989214944
	125796989214896 [label=TBackward0]
	125796989215616 -> 125796989214896
	125798653314464 [label="fc_layers.2.weight
 (84, 120)" fillcolor=lightblue]
	125798653314464 -> 125796989215616
	125796989215616 [label=AccumulateGrad]
	125796989214800 -> 125796989214608
	125796989214800 [label=TBackward0]
	125796989215424 -> 125796989214800
	125796999245776 [label="fc_layers.4.weight
 (10, 84)" fillcolor=lightblue]
	125796999245776 -> 125796989215424
	125796989215424 [label=AccumulateGrad]
	125796989214704 -> 125796978697840
}
